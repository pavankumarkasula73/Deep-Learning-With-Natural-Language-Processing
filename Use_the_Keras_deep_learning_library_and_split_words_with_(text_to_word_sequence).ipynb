{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwysmXT48vLTIDEvlQKuyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavankumarkasula73/Deep-Learning-With-Natural-Language-Processing/blob/main/Use_the_Keras_deep_learning_library_and_split_words_with_(text_to_word_sequence).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Keras**"
      ],
      "metadata": {
        "id": "UEi3cN_Wd4LA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T9YR1FaSrq6W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68c4c43-514a-4948-87e1-422b25055ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Required Libraries**"
      ],
      "metadata": {
        "id": "4TEEXz6td8fJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HXKtBBZIeCeg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the Dataset**"
      ],
      "metadata": {
        "id": "Qt7p-gsveI5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset\n",
        "texts = [\n",
        "    \"Keras is an open-source software library that provides a Python interface for artificial neural networks.\",\n",
        "    \"Keras acts as an interface for the TensorFlow library.\",\n",
        "    \"It was developed by François Chollet, a Google engineer.\",\n",
        "    \"Keras allows for easy and fast prototyping, supports both convolutional networks and recurrent networks, and runs seamlessly on CPU and GPU.\"\n",
        "]"
      ],
      "metadata": {
        "id": "QnQdpXSNeKw0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocess the Text Data**"
      ],
      "metadata": {
        "id": "cLvuwxK6eOqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text data\n",
        "word_sequences = [text_to_word_sequence(text) for text in texts]\n",
        "\n",
        "# Print the result\n",
        "for i, sequence in enumerate(word_sequences):\n",
        "    print(f\"Text {i+1}: {sequence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZet6IRPeSdH",
        "outputId": "b48e60c3-a4a8-4084-9e04-812d4d0d5a80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: ['keras', 'is', 'an', 'open', 'source', 'software', 'library', 'that', 'provides', 'a', 'python', 'interface', 'for', 'artificial', 'neural', 'networks']\n",
            "Text 2: ['keras', 'acts', 'as', 'an', 'interface', 'for', 'the', 'tensorflow', 'library']\n",
            "Text 3: ['it', 'was', 'developed', 'by', 'françois', 'chollet', 'a', 'google', 'engineer']\n",
            "Text 4: ['keras', 'allows', 'for', 'easy', 'and', 'fast', 'prototyping', 'supports', 'both', 'convolutional', 'networks', 'and', 'recurrent', 'networks', 'and', 'runs', 'seamlessly', 'on', 'cpu', 'and', 'gpu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenize the Text Data**"
      ],
      "metadata": {
        "id": "qXU3WYi6e9is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Print the sequences\n",
        "for i, sequence in enumerate(sequences):\n",
        "    print(f\"Text {i+1} sequence: {sequence}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibfzkgqVe-5a",
        "outputId": "de1c884b-ad5d-45d8-cce7-c27899473e13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1 sequence: [2, 9, 5, 10, 11, 12, 6, 13, 14, 7, 15, 8, 3, 16, 17, 4]\n",
            "Text 2 sequence: [2, 18, 19, 5, 8, 3, 20, 21, 6]\n",
            "Text 3 sequence: [22, 23, 24, 25, 26, 27, 7, 28, 29]\n",
            "Text 4 sequence: [2, 30, 3, 31, 1, 32, 33, 34, 35, 36, 4, 1, 37, 4, 1, 38, 39, 40, 41, 1, 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pad the Sequences**"
      ],
      "metadata": {
        "id": "GLZG9de5fB9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences\n",
        "max_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length)\n",
        "\n",
        "# Print the padded sequences\n",
        "print(\"Padded sequences:\")\n",
        "print(padded_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krVdGx7pfG3b",
        "outputId": "4d37d382-aae4-49d8-ba1f-c72f471ef77e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded sequences:\n",
            "[[ 0  0  0  0  0  2  9  5 10 11 12  6 13 14  7 15  8  3 16 17  4]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  2 18 19  5  8  3 20 21  6]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 22 23 24 25 26 27  7 28 29]\n",
            " [ 2 30  3 31  1 32 33 34 35 36  4  1 37  4  1 38 39 40 41  1 42]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define the model**"
      ],
      "metadata": {
        "id": "5qwLdSpxfJh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_length))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhqh40gmfUfw",
        "outputId": "b4496a6f-8f53-4125-944c-f3ab42de1247"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 21, 50)            2150      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22401 (87.50 KB)\n",
            "Trainable params: 22401 (87.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **prepare data for training**"
      ],
      "metadata": {
        "id": "fOYK_wvJfYrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample labels (e.g., binary classification)\n",
        "labels = np.array([1, 0, 1, 0])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CmqGRN2jfd2O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the model**"
      ],
      "metadata": {
        "id": "r_SmoYgFfjBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=2, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uleAPTLfl9H",
        "outputId": "ddc3f7cd-8418-46e5-be02-67f235860e4a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 3s 613ms/step - loss: 0.6957 - accuracy: 0.3333 - val_loss: 0.7050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6847 - accuracy: 0.6667 - val_loss: 0.7179 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6743 - accuracy: 0.6667 - val_loss: 0.7328 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6665 - accuracy: 0.6667 - val_loss: 0.7495 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6535 - accuracy: 0.6667 - val_loss: 0.7661 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6383 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6206 - accuracy: 1.0000 - val_loss: 0.8151 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6030 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.5697 - accuracy: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5321 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a7a11ee2fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate the model**"
      ],
      "metadata": {
        "id": "okZ_LWm3ftfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdOGGimdfwn5",
        "outputId": "1a7d2436-17cb-4564-bb4d-952f09b9be48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 199ms/step - loss: 1.0170 - accuracy: 0.0000e+00\n",
            "Test Loss: 1.0169551372528076\n",
            "Test Accuracy: 0.0\n"
          ]
        }
      ]
    }
  ]
}